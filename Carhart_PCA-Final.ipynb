{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASDAQ Composite Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #to deal with the data from the yahoo finance api\n",
    "import numpy as np #for tensorflow and sklearn\n",
    "import datetime as dt #datetime adjusting\n",
    "import pandas_datareader.data as web #api for tick price data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignore warnings\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier #for seeing which cluster a small, value, momentum stock would fall in\n",
    "from sklearn.metrics import accuracy_score #the accuracy score of the k nearest neighbor classifier (based on clusters)\n",
    "from sklearn.cluster import KMeans # might end up using this library\n",
    "import tensorflow as tf #machine learning libraries used for data splitting and model creation\n",
    "from tensorflow import keras #for the deep learning model at the end\n",
    "from sklearn.preprocessing import MinMaxScaler #normalize data\n",
    "from sklearn.model_selection import train_test_split #split data\n",
    "from sklearn.metrics import r2_score #metric\n",
    "from tensorflow.keras.models import Sequential, Model #deep learning sequential model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Concatenate #layers for deep learing \n",
    "from keras import optimizers #optimizer for deep learning model (will most likely end up being Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning / Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.read_excel('nasdaq_comp2013.xlsx').dropna() #dropping nan (loading in NASDAQ 2013/12/31)\n",
    "def data(excel): #function for cleaning data\n",
    "    excel['Ticker'] = excel.Ticker.str.split(' ').str[0] #splitting the rest off the Ticker for querying\n",
    "    excel = excel[['Ticker','Market Cap','P/B','1Y Tot Ret']] #these are the features I want for the end\n",
    "    return excel.take(np.random.permutation(len(excel))[:150]) #taking a random 100 selection of the NASDAQ Composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_returns(df): #queries all the returns for 2014 to 2019 based on size, value, and momentum\n",
    "    failed = [] #failed list\n",
    "    passed = [] #passed list\n",
    "    data = pd.DataFrame() #create a dataframe for the loop\n",
    "    for ticker in df['Ticker'].values: #loop through all the tickers \n",
    "        try: #try clause\n",
    "            data[ticker] = web.DataReader(ticker, \"yahoo\", '2014-01-01', '2016-01-01')[\"Adj Close\"] #6 year tick price data\n",
    "            passed.append(ticker) #append passed tickers to the list\n",
    "        except (IOError, KeyError): #error\n",
    "            failed.append(ticker) #failed tickers\n",
    "    return data #average yearly return of all found securities in the database\n",
    "\n",
    "r = data(excel) #clean the data collected from Bloomberg\n",
    "df = total_returns(r) #a few of these stocks will not be in the API\n",
    "r = r.set_index('Ticker') #set index as Ticker to combine the datasets\n",
    "data = ((df.iloc[-1]-df.iloc[0])/df.iloc[0])*100 #return after two years\n",
    "r = r.loc[data.index] #making sure both datasets have the same tickers in each \n",
    "main = pd.merge(r, pd.DataFrame(data), left_index=True, right_index=True).dropna() #merging and dropping any null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data Further for Better Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxima = 10 #10 percent return (negative and positive will be where I will classify each return)\n",
    "main.loc[(main[0] >= (-maxima)) & (main[0] <= 0),'Label'] = 2 #greater than (-10) but less than 0\n",
    "main.loc[(main[0] >= (0)) & (main[0] <= maxima),'Label'] = 3 #greater than 0 but less than 10\n",
    "main.loc[(main[0] > maxima),'Label'],main.loc[(main[0] < -maxima),'Label'] = 4,1 # 4 is greatest returns\n",
    "main.loc[(main['1Y Tot Ret'] > 0),'1Y Tot Ret'] = 1 #momentum stock\n",
    "main.loc[(main['1Y Tot Ret'] < 0),'1Y Tot Ret'] = 0 #not a momentum stock\n",
    "new = main[['Market Cap','P/B','1Y Tot Ret','Label']] #features I want plus the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1 :  0.333 \n",
      "SMB-HML-UMD:  [2.] \n",
      "\n",
      "k = 2 :  0.333 \n",
      "SMB-HML-UMD:  [2.] \n",
      "\n",
      "k = 3 :  0.333 \n",
      "SMB-HML-UMD:  [2.] \n",
      "\n",
      "k = 4 :  0.385 \n",
      "SMB-HML-UMD:  [2.] \n",
      "\n",
      "k = 5 :  0.436 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n",
      "k = 6 :  0.41 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n",
      "k = 7 :  0.487 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n",
      "k = 8 :  0.436 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n",
      "k = 9 :  0.513 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n",
      "k = 10 :  0.59 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n",
      "k = 11 :  0.564 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n",
      "k = 12 :  0.564 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n",
      "k = 13 :  0.564 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n",
      "k = 14 :  0.59 \n",
      "SMB-HML-UMD:  [4.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def nearest_neighbors(new):\n",
    "    X = new.iloc[:,0:3] #size, value, and momentum features\n",
    "    y = new.iloc[:,3] #return labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.33, random_state=42) #splitting the data\n",
    "    for k in list(range(1,15)): #using a different value of k \n",
    "        neigh = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train) #fitting model to training data\n",
    "        y_pred = neigh.predict(X_test) #predicting using the testing features \n",
    "        acc = accuracy_score(y_test,y_pred) #accuracy score of 50% shows that these features show some merit\n",
    "        test = neigh.predict([[2000000000,5,1]]) #small cap, value p/b ratio (it would depend on sector), and momentum stock \n",
    "        print('k =', k, ': ', round(acc,3),'\\nSMB-HML-UMD: ',test,'\\n') #small, value, momentum stock to fit into what cluster\n",
    "        \n",
    "nearest_neighbors(new) #most would fit into the highest earning cluster (especially once the model has a higher accuracy score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Security based on Carhart Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyst strong buy recommendation, small cap, p/b ratio under 5, and year to date positive returns (momentum)\n",
    "import requests\n",
    "def screener():\n",
    "    url = 'https://finviz.com/screener.ashx?v=141&f=an_recom_strongbuy,cap_small,fa_pb_u5,ta_perf_52wup&o=-perf52w'\n",
    "    resp = requests.get(url,headers={'user-agent': 'my-app/0.0.1'}) #scraping the url\n",
    "    l = [] #empty list to be added to after scraping from FinViz\n",
    "    for ticker in resp.text.split('href=\"quote.ashx?t='):\n",
    "        tickers = (ticker.split('&ty')[0]) #selecting security with carhart four factors (best ytd performance)\n",
    "        l.append(tickers) #getting all the tickers within the screener\n",
    "    return list(set(l[-320:])) #removing the many duplicate tickers within the screener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||Chosen Security: IDYA|||\n",
      "Value Mean Absolute Percentage Error ['12.50', '10.53', '8.05', '5.97', '5.91']\n",
      "The predicted stock price for IDYA tomorrow is $16.4.\n",
      "Buy:  16.4 > 16.24 \n",
      "PCT DIFF:  0.96 %\n",
      "|||Chosen Security: VRNA|||\n",
      "Value Mean Absolute Percentage Error ['7.94', '4.98', '5.97', '4.07', '4.69']\n",
      "The predicted stock price for VRNA tomorrow is $8.06.\n",
      "Buy:  8.06 > 7.9 \n",
      "PCT DIFF:  2.08 %\n",
      "|||Chosen Security: ITCI|||\n",
      "Value Mean Absolute Percentage Error ['11.62', '6.07', '4.77', '5.25', '5.70']\n",
      "The predicted stock price for ITCI tomorrow is $24.52.\n",
      "Sell:  24.52 < 24.58 \n",
      "PCT DIFF:  -0.24 %\n",
      "|||Chosen Security: BWMX|||\n",
      "Value Mean Absolute Percentage Error ['23.68', '16.67', '8.73', '3.43', '2.56']\n",
      "The predicted stock price for BWMX tomorrow is $29.81.\n",
      "Sell:  29.81 < 29.85 \n",
      "PCT DIFF:  -0.14 %\n",
      "|||Chosen Security: NLTX|||\n",
      "Value Mean Absolute Percentage Error ['9.59', '4.99', '4.70', '4.50', '4.63']\n",
      "The predicted stock price for NLTX tomorrow is $12.07.\n",
      "Buy:  12.07 > 12.0 \n",
      "PCT DIFF:  0.59 %\n",
      "|||Chosen Security: HOFT|||\n",
      "Value Mean Absolute Percentage Error ['11.96', '4.18', '2.39', '2.64', '2.61']\n",
      "The predicted stock price for HOFT tomorrow is $31.81.\n",
      "Sell:  31.81 < 33.14 \n",
      "PCT DIFF:  -4.03 %\n",
      "|||Chosen Security: TIGR|||\n",
      "Value Mean Absolute Percentage Error ['7.03', '6.06', '4.80', '5.34', '8.16']\n",
      "The predicted stock price for TIGR tomorrow is $5.04.\n",
      "Sell:  5.04 < 5.35 \n",
      "PCT DIFF:  -5.82 %\n",
      "|||Chosen Security: SHYF|||\n",
      "Value Mean Absolute Percentage Error ['9.95', '3.67', '3.65', '4.13', '3.50']\n",
      "The predicted stock price for SHYF tomorrow is $26.91.\n",
      "Sell:  26.91 < 27.69 \n",
      "PCT DIFF:  -2.83 %\n",
      "|||Chosen Security: ALBO|||\n",
      "Value Mean Absolute Percentage Error ['6.17', '5.19', '5.08', '4.62', '4.38']\n",
      "The predicted stock price for ALBO tomorrow is $39.95.\n",
      "Buy:  39.95 > 39.77 \n",
      "PCT DIFF:  0.45 %\n",
      "|||Chosen Security: MITK|||\n",
      "Value Mean Absolute Percentage Error ['13.88', '3.09', '3.07', '3.63', '2.96']\n",
      "The predicted stock price for MITK tomorrow is $12.78.\n",
      "Sell:  12.78 < 13.11 \n",
      "PCT DIFF:  -2.49 %\n",
      "|||Chosen Security: PETQ|||\n",
      "Value Mean Absolute Percentage Error ['13.38', '4.75', '3.94', '4.00', '4.05']\n",
      "The predicted stock price for PETQ tomorrow is $30.44.\n",
      "Sell:  30.44 < 31.72 \n",
      "PCT DIFF:  -4.03 %\n",
      "|||Chosen Security: WLDN|||\n",
      "Value Mean Absolute Percentage Error ['5.70', '3.00', '3.03', '3.29', '3.02']\n",
      "The predicted stock price for WLDN tomorrow is $37.93.\n",
      "Sell:  37.93 < 38.07 \n",
      "PCT DIFF:  -0.37 %\n",
      "|||Chosen Security: CBAY|||\n",
      "Value Mean Absolute Percentage Error ['10.53', '7.86', '7.50', '7.22', '7.04']\n",
      "The predicted stock price for CBAY tomorrow is $6.83.\n",
      "Sell:  6.83 < 6.84 \n",
      "PCT DIFF:  -0.22 %\n",
      "|||Chosen Security: NGVC|||\n",
      "Value Mean Absolute Percentage Error ['14.97', '7.81', '3.42', '3.42', '4.04']\n",
      "The predicted stock price for NGVC tomorrow is $13.98.\n",
      "Buy:  13.98 > 13.8 \n",
      "PCT DIFF:  1.28 %\n",
      "|||Chosen Security: VIVO|||\n",
      "Value Mean Absolute Percentage Error ['10.45', '2.55', '2.64', '2.95', '2.66']\n",
      "The predicted stock price for VIVO tomorrow is $18.96.\n",
      "Buy:  18.96 > 18.59 \n",
      "PCT DIFF:  1.99 %\n",
      "|||Chosen Security: CTRN|||\n",
      "Value Mean Absolute Percentage Error ['8.71', '4.93', '4.21', '3.93', '3.30']\n",
      "The predicted stock price for CTRN tomorrow is $39.8.\n",
      "Sell:  39.8 < 42.12 \n",
      "PCT DIFF:  -5.5 %\n",
      "|||Chosen Security: TA|||\n",
      "Value Mean Absolute Percentage Error ['9.83', '3.91', '3.74', '3.78', '3.72']\n",
      "The predicted stock price for TA tomorrow is $33.63.\n",
      "Buy:  33.63 > 33.39 \n",
      "PCT DIFF:  0.71 %\n",
      "|||Chosen Security: VBIV|||\n",
      "Value Mean Absolute Percentage Error ['20.79', '6.94', '6.98', '6.53', '6.54']\n",
      "The predicted stock price for VBIV tomorrow is $3.2.\n",
      "Buy:  3.2 > 3.12 \n",
      "PCT DIFF:  2.46 %\n",
      "|||Chosen Security: QNST|||\n",
      "Value Mean Absolute Percentage Error ['7.61', '3.86', '3.74', '3.98', '3.85']\n",
      "The predicted stock price for QNST tomorrow is $20.71.\n",
      "Sell:  20.71 < 20.72 \n",
      "PCT DIFF:  -0.04 %\n",
      "|||Chosen Security: CAI|||\n",
      "Value Mean Absolute Percentage Error ['12.80', '4.29', '3.92', '3.96', '4.02']\n",
      "The predicted stock price for CAI tomorrow is $33.55.\n",
      "Sell:  33.55 < 34.2 \n",
      "PCT DIFF:  -1.91 %\n"
     ]
    }
   ],
   "source": [
    "def data(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end)[['Adj Close','High','Low']]\n",
    "    df['sm3'] = df['Adj Close'].rolling(window=3).mean() #3 day moving average\n",
    "    df['sm9'] = df['Adj Close'].rolling(window=9).mean() #9 day moving average\n",
    "    drivers = ['^VIX','SPY'] #vix and the market benchmark\n",
    "    portfolio = pd.DataFrame() #create an emy dataframe to place data \n",
    "    failed = [] #empty list for failed queries\n",
    "    for stock in drivers: #for loop for all the features I want to try\n",
    "        try: #try clause just in case it failed\n",
    "            portfolio[stock] = web.DataReader(stock,'yahoo',start,end)['Adj Close'] #adj close of each feature\n",
    "            portfolio[f'{stock} sma3'] = portfolio[stock].rolling(window=3).mean() #moving averages as features\n",
    "            portfolio[f'{stock} sma9'] = portfolio[stock].rolling(window=9).mean()\n",
    "            portfolio = portfolio.drop([stock],axis=1) #drop the adj close price\n",
    "        except:\n",
    "            failed.append(stock) #add failed query ticker to list\n",
    "            print(f'{failed} was not properly calculated for. Are you sure this ticker is on an exchange?')\n",
    "    data = pd.concat([df,portfolio],axis = 1).dropna() #combine both dataframes\n",
    "    df['Target'] = df['Adj Close'].shift(-1) #shift adj close back 1: we are forecasting one day into the future\n",
    "    df = df.drop(['Adj Close','High','Low'],axis =1) #drop these bc nn works better \n",
    "    return df.dropna() #no null values\n",
    "\n",
    "\n",
    "\n",
    "def predict(df,pred_df):\n",
    "    X = df[df.columns] #feature data\n",
    "    del X['Target'] #don't want target variable in training data\n",
    "    Y = df[['Target']] #label data\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,random_state=50,test_size=0.2) #training and testing\n",
    "    x_val,x_test,y_val,y_test = train_test_split(x_test,y_test,random_state=50,test_size=0.5) #test and validation\n",
    "    model = Sequential() #basic sequential model \n",
    "    model.add(Dense(100, input_dim=x_train.shape[1], #need the input shape of the data in tensorflow 2x\n",
    "                        activation=tf.nn.leaky_relu, # was better than relu\n",
    "                        kernel_initializer='he_normal')) #initializer to stop from vanishing/exploding gradient\n",
    "    model.add(Dense(75, input_dim=100, #100 'neurons' in the input layer\n",
    "                        activation=tf.nn.leaky_relu, \n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.add(Dense(50, input_dim=75, #75 'neurons' in the first hidden layer\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.add(Dense(25, input_dim=50, #50 'neurons' in the second hidden layer\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.add(Dense(1, activation=tf.nn.leaky_relu, #only one answer so you need one 'neuron'\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.compile(loss='mean_squared_error', #mse loss function\n",
    "                      optimizer='adam', #adam optimizer\n",
    "                      metrics=['mape']) #mean absolute percentage error metric to determine the performance of the model\n",
    "    scaler = MinMaxScaler() #normalize the data since it is pretty different in terms of share price\n",
    "    x_train_scaled = scaler.fit_transform(x_train) #apply the normalizer to the training features\n",
    "    history = model.fit(x_train, y_train,  #fit the training data to the model\n",
    "                        validation_data=(x_val, y_val), #validation data to better see how the model is doing\n",
    "                        batch_size=32,\n",
    "                        epochs=5,\n",
    "                        verbose=0)\n",
    "    pred_features = pred_df.iloc[-1] #these will be in the pred_data function \n",
    "    prediction = model.predict(np.array([pred_features])) #need it in numpy array \n",
    "    mape = history.history['val_mape'] #getting the mean absolute percentage error to see which is the lowest\n",
    "    mape = [\"%.2f\" % i for i in mape] #rounding it to two decimal places\n",
    "    print(f\"Value Mean Absolute Percentage Error {mape}\") #print statement to look cleaner once the code is run\n",
    "    print(f'The predicted stock price for {ticker.upper()} tomorrow is ${round(float(prediction[0]),2)}.')\n",
    "    if float(prediction[0])>float(df['Target'].iloc[-1:].values): #buy or sell statement based on model prediction and real time tick data\n",
    "        print('Buy: ', round(float(prediction[0]),2), '>',round(float(df['Target'].iloc[-1:].values),2),\n",
    "              '\\nPCT DIFF: ',round((float(prediction[0]) - float(df['Target'].iloc[-1:].values))/float(df['Target'].iloc[-1:].values)*100,2),'%',)\n",
    "    else:\n",
    "        print('Sell: ', round(float(prediction[0]),2), '<',round(float(df['Target'].iloc[-1:].values),2),\n",
    "              '\\nPCT DIFF: ',round((float(prediction[0]) - float(df['Target'].iloc[-1:].values))/float(df['Target'].iloc[-1:].values)*100,2),'%')\n",
    "\n",
    "\n",
    "\n",
    "def pred_data(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end)[['Adj Close','High','Low']] #query data of target security\n",
    "    df['sm3'] = df['Adj Close'].rolling(window=3).mean() #moving averages (3 day)\n",
    "    df['sm9'] = df['Adj Close'].rolling(window=9).mean() #moving averages (9 day)\n",
    "    drivers = ['^VIX','SPY'] #volatility and sp500\n",
    "    portfolio = pd.DataFrame() #create an emy dataframe to place data \n",
    "    failed = [] #empty list for failed queries\n",
    "    for stock in drivers: #for loop for all the features I want to try\n",
    "        try: #try clause just in case it failed\n",
    "            portfolio[stock] = web.DataReader(stock,'yahoo',start,end)['Adj Close'] #adj close of each feature\n",
    "            portfolio[f'{stock} sma3'] = portfolio[stock].rolling(window=3).mean() #moving averages as features\n",
    "            portfolio[f'{stock} sma9'] = portfolio[stock].rolling(window=9).mean()\n",
    "            portfolio = portfolio.drop([stock],axis=1) #drop the adj close price\n",
    "        except:\n",
    "            failed.append(stock) #add failed query ticker to list\n",
    "            print(f'{failed} was not properly calculated for. Are you sure this ticker is on an exchange?')\n",
    "    data = pd.concat([df,portfolio],axis = 1).dropna() #combine both dataframes\n",
    "    df = df.drop(['Adj Close','High','Low'],axis = 1)\n",
    "    return df.dropna()\n",
    "\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    tf.get_logger().setLevel('ERROR') #getting rid of tensorflow errors\n",
    "    tickers = screener() #target securities that fit the screener of small, value, momentum, and analyst strong buy\n",
    "    for ticker in tickers: #looping through screened stocks\n",
    "        print(f'|||Chosen Security: {ticker}|||') #printing the stock that is being tested by the model\n",
    "        try: #try clause just in case API doesn't have that ticker\n",
    "            start = dt.datetime.now() - dt.timedelta(days=365*5) #5 year time frame\n",
    "            end = dt.datetime.now() #today\n",
    "            predict(data(ticker,start,end),pred_data(ticker,start,end)) #calling the function we want to predict the target security\n",
    "        except (IOError, KeyError): #error\n",
    "            pass #keep running if an error is raised"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
